---
title: "CHAI: consensus Clustering tHrough similArIty matrIces for single cell type identification"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{my-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
# Introduction
CHAI (consensus Clustering tHrough similArIty matrIces for single cell type identification) is a consensus clustering framework that offers two methods for consensus clustering: Clustering Similarity Partitioning Algorithm (CSPA) and Similarity Network Fusion (SNF).
This vignette demonstrates a standard workflow for running both CSPA and SNF for the purpose of consensus clustering. 

# Install Dependencies
All CRAN related dependencies are installed with the installion of CHAI. However you will need to install some other dependencies independently from BioConductor and GitHub. Below is how to do so for each package.
```{r setup, eval=FALSE}
# Install scSHC
devtools::install_github("igrabski/sc-SHC")
# Install RaceID
devtools::install_github("dgrun/RaceID3_StemID2_package")
# Install SC3
if (!require("BiocManager", quietly = TRUE)) {
    install.packages("BiocManager")
}
BiocManager::install("SC3")
# Install SingleCellExperiment
BiocManager::install("SingleCellExperiment")

remotes::install_github("corceslab/CHOIR", ref="main", repos = BiocManager::repositories(), upgrade = "never")
```
Now, all packages should be installed.
```{r, message=FALSE}
library(chai)
library(scSHC)
library(RaceID)
library(SC3)
library(SingleCellExperiment)
library(CHOIR)
```
# Data Loading and Preprocessing
CHAI accepts a SingleCellExperiment object as input for running all clustering algorithms. Creating a SingleCellExperiment object for single cell RNA-seq data is well documented, here is an example for creating one using a single cell matrix, where rows are genes and columns are cells. 
Be sure to load the counts and logcounts into the single cell experiment object. 

For test data, we provide a subsampled 100 cell dataset from the widely used Baron datasets. This is accessible in the data section of the CHAI repo.

```{r, eval=FALSE}
# Load data
sampled_data <- read.csv("data/sampled_data.csv", row.names = 1)

# Create SingleCellExperiment object
sce <- SingleCellExperiment(assays = list(counts = as.matrix(sampled_data)))
# Add logcounts 
sce <- scuttle::logNormCounts(sce)

```

# Run Clustering Algorithms
The CHAI workflow currently supports 6 state-of-the-art clustering methods: Seurat, scSHC, Spectrum, SC3, RaceID and CHOIR. For Seurat we run two clustering algorithms, Louvain and SLC. To run all algorithms, we provide a wrapper function that takes a SingleCellExperiment object as input. 

We are aware that scSHC does not run on some Windows machine at the moment due to the mccores error. For now this function will throw an error and not run, but the rest of the function will still execute. 

```{r, eval=FALSE}
# Run All Clustering Algorithms
get_clust_assignments(sce, out_dir = getwd())
```

All clustering assignments will be written to a newly created alg_clust_assign subdirectory within the current working directory, or another directory specified in the out_dir parameter. 
The format for the clustering assignments is a .csv file containing the cell names in column "cells", and the cluster assignments in the column "clust_assign". 

You also have the ability to run individual clustering algorithms. Simply call ```{algorithm_name}_assign_func(sce, out_dir)```. Here is an example for Seurat.
```{r, eval=FALSE}
# Run Just Seurat Clustering Algorithm. 
seurat_assign_func(sce, out_dir = getwd())
```

# Create Binary Similarity Matrices

Both CSPA and SNF consensus clustering are based on binary similarity matrices. In brief, we create a similarity matrix for each cluster assignment with the following rules:

1. If two cells are assigned the same cluster, assign a score of 1. 
2. If two cells are not assigned the same cluster, assign a score of zero. 

Therefore we are able to create a binary similarity matrix for each clustering algorithm in the CHAI workflow. We store each matrix in a list format, which makes them easier to access for downstream functions. 

The function to create the list of similarity matrices takes as parameter the home directory, which must be the parent folder of the previously created "alg_clust_assign" directory. This parameter defaults to the current working directory. 
```{r, eval=FALSE}
# Generate list of binary similarity matrices 
similarity_matrix_list = create_matrix_list(getwd())
```

# Run CSPA or SNF

Running either CSPA or SNF is very simple using the CHAI infrustructure. 

To run CSPA, we must create an average ranking matrix of each binary similarity matrix in the similarity_matrix_list. 

```{r, eval=FALSE}
# Generate list of binary similarity matrices 
cspa_average_matrix <- create_average_matrix(similarity_matrix_list)
```

To run SNF, we must call the SNF function on the similarity_matrix_list. 

```{r, eval=FALSE}
# Generate list of binary similarity matrices 
snf_matrix <- create_snf_matrix(similarity_matrix_list)
```

# Run Spectral Clustering for Consensus Clustering Assignments 

CHAI supports running Spectral Clustering on either the cspa_average_matrix or the snf_matrix. Spectral Clustering requires the specification of a "K" partitioning of the graph, which will be the number of cell clusters in this case. 

If a user already knows the true number of clusters in the dataset, they can simply run Spectral Clustering on either matrix. We use the snf_matrix as an example here, but it is interchangable with the cspa_average_matrix in the case of this function. 
```{r, eval=FALSE}
# Run Spectral clustering on snf_matrix. To run on cspa_average_matrix, replace snf_matrix with cspa_average_matrix in this function. 
true_k <- 9
snf_clusters <- spectral_clustering(snf_matrix, true_k)
```

If the true number of clusters is not known, users can determine the "best_k" for Spectral Clustering by evaluating the optimal silhouette score. The CHAI workflow provides a method to do so. 

```{r, eval=FALSE}

# Determine best K through silhouette score. 
best_k <- calc_silhouette_scores(snf_matrix, 15)

# To run on cspa_average_matrix, replace snf_matrix with cspa_average_matrix in this function. 
snf_clusters <- spectral_clustering(snf_matrix, best_k)
```

# Evaluation

The CHAI workflow currently supports ARI as an evaluation metric. We will add NMI shortly. 

Here is how to generate an adjusted rand index table/bar graph for CHAI_CSPA, CHAI_SNF, and the rest of the algorithms, using the ```eval_function``` in CHAI.

```{r, eval = FALSE}
# Create a dataframe for ARI, to make into bargraph

ari_table <- data.frame("Algorithm" = c("CHAI_CSPA", "CHAI_SNF"), "ARI" = c(eval_function(cspa_clusters@.Data, ground_truth$clust_assign),eval_function(snf_clusters@.Data, ground_truth$clust_assign)))

# Iterate over the rest of alg_clust_assign and add to the ari_table
setwd("alg_clust_assign")
for (file in list.files(getwd())) {
    # Read the CSV file
    assign_file <- read.csv(file)
    # Evaluate function and calculate ARI
    ari <- eval_function(assign_file$clust_assign, sdf_metadata$Graph.based)
    # Add new row to ari_table
    new_row <- data.frame("Algorithm" = gsub("_assign.csv", "", file), "ARI" = ari, stringsAsFactors = FALSE)
    ari_table <- rbind(ari_table, new_row)
}
# Change home directory back to parent folder of alg_clust_assign
setwd(home_dir)

# Create bargraph using ggplot2
library(ggplot2)
plot <- ggplot(ari_table, aes(x = Algorithm, y = ARI, fill = Algorithm)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("CHAI_CSPA" = "darkgreen", "CHAI_SNF" = "darkgreen")) + # Set colors
  labs(x = "Algorithm", y = "ARI", title = "ARI Evaluation for Dataset") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggsave("ari_eval_plot", plot = plot, width = 10, height = 8)

write.csv(ari_table, "ari_table.csv")
```

We recommend also saving the CSPA and SNF clustering assignments for future use. 

```{r, eval = FALSE}
cspa_labels <- cbind(colnames(data), cspa_clusters@.Data)
snf_labels <- cbind(colnames(data), snf_clusters@.Data)

write.csv(cspa_labels, "cspa_assign.csv")
write.csv(snf_labels, "snf_assign.csv")
```

# Session Info 

```{r}
sessionInfo()
```
# TODO: Add Visualization and References. 